# Reinforcement Learning

| Publish Date | Title | Authors | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2021-11-05**|**Regular Decision Processes for Grid Worlds**|Nicky Lenaers et.al.|[2111.03647v1](http://arxiv.org/abs/2111.03647v1)|null|
|**2021-11-05**|**Adaptive Low-Pass Filtering using Sliding Window Gaussian Processes**|Alejandro J. Ordóñez-Conejo et.al.|[2111.03617v1](http://arxiv.org/abs/2111.03617v1)|null|
|**2021-11-05**|**Cross Modality 3D Navigation Using Reinforcement Learning and Neural Style Transfer**|Cesare Magnetti et.al.|[2111.03485v1](http://arxiv.org/abs/2111.03485v1)|**[link](https://github.com/cesaremagnetti/automaticusnavigation)**|
|**2021-11-05**|**Supervised Advantage Actor-Critic for Recommender Systems**|Xin Xin et.al.|[2111.03474v1](http://arxiv.org/abs/2111.03474v1)|null|
|**2021-11-05**|**Perturbational Complexity by Distribution Mismatch: A Systematic Analysis of Reinforcement Learning in Reproducing Kernel Hilbert Space**|Jihao Long et.al.|[2111.03469v1](http://arxiv.org/abs/2111.03469v1)|null|
|**2021-11-05**|**Reinforcement Learning Approach to Shortcuts between Thermodynamic States with Extra Constraints**|Rongxing Xu et.al.|[2111.03432v1](http://arxiv.org/abs/2111.03432v1)|null|
|**2021-11-05**|**Learning to Cooperate with Unseen Agent via Meta-Reinforcement Learning**|Rujikorn Charakorn et.al.|[2111.03431v1](http://arxiv.org/abs/2111.03431v1)|null|
|**2021-11-05**|**FINN.no Slates Dataset: A new Sequential Dataset Logging Interactions, allViewed Items and Click Responses/No-Click for Recommender Systems Research**|Simen Eide et.al.|[2111.03340v1](http://arxiv.org/abs/2111.03340v1)|**[link](https://github.com/finn-no/recsys-slates-dataset)**|
|**2021-11-04**|**Value Function Spaces: Skill-Centric State Abstractions for Long-Horizon Reasoning**|Dhruv Shah et.al.|[2111.03189v1](http://arxiv.org/abs/2111.03189v1)|null|
|**2021-11-04**|**Infinite Time Horizon Safety of Bayesian Neural Networks**|Mathias Lechner et.al.|[2111.03165v1](http://arxiv.org/abs/2111.03165v1)|**[link](https://github.com/mlech26l/bayesian_nn_safety)**|
|**2021-11-04**|**Successor Feature Neural Episodic Control**|David Emukpere et.al.|[2111.03110v1](http://arxiv.org/abs/2111.03110v1)|null|
|**2021-11-04**|**Learning to Manipulate Tools by Aligning Simulation to Video Demonstration**|Kateryna Zorina et.al.|[2111.03088v1](http://arxiv.org/abs/2111.03088v1)|null|
|**2021-11-04**|**Generalization in Dexterous Manipulation via Geometry-Aware Multi-Task Learning**|Wenlong Huang et.al.|[2111.03062v1](http://arxiv.org/abs/2111.03062v1)|null|
|**2021-11-04**|**Imagine Networks**|Seokjun Kim et.al.|[2111.03048v2](http://arxiv.org/abs/2111.03048v2)|null|
|**2021-11-04**|**B-Pref: Benchmarking Preference-Based Reinforcement Learning**|Kimin Lee et.al.|[2111.03026v1](http://arxiv.org/abs/2111.03026v1)|**[link](https://github.com/rll-research/b-pref)**|
|**2021-11-04**|**Towards an Understanding of Default Policies in Multitask Policy Optimization**|Ted Moskovitz et.al.|[2111.02994v1](http://arxiv.org/abs/2111.02994v1)|null|
|**2021-11-04**|**Causal versus Marginal Shapley Values for Robotic Lever Manipulation Controlled using Deep Reinforcement Learning**|Sindre Benjamin Remman et.al.|[2111.02936v1](http://arxiv.org/abs/2111.02936v1)|null|
|**2021-11-04**|**Model-Free Risk-Sensitive Reinforcement Learning**|Grégoire Delétang et.al.|[2111.02907v1](http://arxiv.org/abs/2111.02907v1)|null|
|**2021-11-04**|**Attacking Deep Reinforcement Learning-Based Traffic Signal Control Systems with Colluding Vehicles**|Ao Qu et.al.|[2111.02845v1](http://arxiv.org/abs/2111.02845v1)|null|
|**2021-11-04**|**Towards Learning to Speak and Hear Through Multi-Agent Communication over a Continuous Acoustic Channel**|Kevin Eloff et.al.|[2111.02827v1](http://arxiv.org/abs/2111.02827v1)|null|

